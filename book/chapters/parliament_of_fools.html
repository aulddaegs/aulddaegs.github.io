<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>A Parliament of Fools
</title>
    <link rel="stylesheet" href="../book.css">
</head>
<body>
    <button id="dosbutton">*</button>
    <div class="book-info">The Savage Computers - Chris Pang<br><a href="../index.html">[Table of Contents]</a></div>
    <h1>A Parliament of Fools
</h1>
    <div class="book-content">
        <p><em>Extract from "A Parliament of Fools: AI-generated Multi-modal Misinformation Networks in an Evolving Media Landscape"</em></p>
<p><em>Abstract</em></p>
<p>Traditionally, models of addressing misinformation treat it as either isolated pieces of misinformation that can be addressed (“debunked”) on an individual basis, or as copies or variations of the same piece of misinformation spread by a single source or actor over a period of time. To the contrast, we posit that the most effective pieces of misinformation (including COVID-19 conspiracies, the Qanon conspiracy, as well as misinformation networks targeting issues like the South Sea and Cryptocurrency) rely on a multimodal and networked model of misinformation where the central lie or deception is perceived to be supported by a variety of different sources using different persuasive techniques and media types (image, newscast, tiktok video etc.). We further propose that the advent of generative AI technology has made creating these multimodal misinformation networks much easier, and we provide some explanations as to our rationale. Our experiments show that setting up GAI tools to generate multi-modal misinformation based on a single short prompt e.g. “a conflict between India and Pakistan in Kashmir” is trivial.</p>
    </div>
    <br>
    <div id="backlink"><a href="../index.html">Back to Table of Contents</a></div>
    <br>
    <br>
    <script src="../js/book.js"></script>
</body>
</html>